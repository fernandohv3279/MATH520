\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{enumitem}
\newcommand{\bld}[1]{\boldsymbol{#1}}

\begin{document}

\title{MATH520 Homework 3}
\author{Fernando}
\date{\today}
\maketitle

\section*{Exercise 8.18}
Let $f:\mathbb{R}^n\to\mathbb{R}$ be given by
$f(x)=\frac{1}{2}\bld{x}^T\bld{Q}\bld{x}-\bld{x}^Tb$, where
$\bld{b}\in\mathbb{R}^n$ and $\bld{Q}$ is a real symmetric positive definite
$n\times n$ matrix. Suppose that we apply the steepest descent method to this
function, with $\bld{x}^{(0)}\neq \bld{Q}^{-1}\bld{b}$. Show that the method
converges in one step, that is, $\bld{x}^{(1)}=\bld{Q}^{-1}\bld{b}$, if and
only if $\bld{x}^{(0)}$ is chosen such that
$\bld{g}^{(0)}=\bld{Q}\bld{x}^{(0)}=\bld{Q}\bld{x}^{(0)}-\bld{b}$ is an
eigenvector of $\bld{Q}$.
\subsection*{Solution}
TODO: CHECK HYPOTHESIS!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
First we note that $\nabla f(\bld{x})=\bld{Q}\bld{x}-\bld{b}$. And thus
\[
\bld{x}^{(1)}=\bld{x}^{(0)}-\alpha_0\nabla
f(\bld{x}^{(0)})=\bld{x}^{(0)}-\alpha_0(\bld{Q}\bld{x}^{(0)}-\bld{b}),
\]
Where $\alpha_0\neq 0$ because $\bld{x}^{(0)}\neq \bld{Q}^{-1}\bld{b}$.
Then
\begin{align*}
	\bld{x}^{(1)}&=\bld{Q}^{-1}\bld{b}\\
	\bld{x}^{(0)}-\alpha_0(\bld{Q}\bld{x}^{(0)}-\bld{b})&=\bld{Q}^{-1}\bld{b}\\
	\bld{Q}(\bld{x}^{(0)}-\alpha_0(\bld{Q}\bld{x}^{(0)}-\bld{b}))&=\bld{b}\\
	\bld{Q}(\bld{Q}\bld{x}^{(0)}-\bld{b}))&=\frac{1}{\alpha_0}(\bld{Q}\bld{x}^{(0)}-\bld{b}).
\end{align*}
\section*{Exercise 8.24}
Given $f:\mathbb{R}^n\to \mathbb{R}$, consider the general iterative algorithm
\[
	\bld{x}^{(k+1)}=\bld{x}^{(k)}+\alpha_k\bld{d}^{(k)},
\]
where $\bld{d}^{(1)},\bld{d}^{(2)},\dots$ are given vectors in $\mathbb{R}^n$
and $\alpha_k$ is chosen to minimize $f(\bld{x}^{(k)}+\alpha \bld{d}^{(k)})$;
that is,
\[
	\alpha_k = \arg \min f(\bld{x}^{(k)}+\alpha \bld{d}^{(k)}).
\]
Show that for each $k$, the vector $\bld{x}^{(k+1)}-\bld{x}^{(k)}$ is
orthogonal to $\nabla f(\bld{x}^{(k+1)})$ (assuming that the gradient exists).
\subsection*{Solution}
Let us define the function
\[
	h(\alpha)=f(\bld{x}^{(k)}+\alpha\bld{d}^{(k)})
\]
then
\[
	h'(\alpha)=\nabla f(x^{(k)}+\alpha \bld{d}^{(k)}) \cdot \bld{d}^{(k)}.
\]
By definition $\alpha_k$ satisfies $h'(\alpha_k)=0$ (FONC) so
\[
	0=h'(\alpha_k)=\nabla f(\bld{x}^{(k)}+\alpha_k \bld{d}^{(k)}) \cdot
	\bld{d}^{(k)} = \nabla f(\bld{x}^{(k+1)}) \cdot
	(\bld{x}^{(k+1)}-\bld{x}^{(k)})
\]
Which is what we wanted to prove.
\section*{Exercise 9.1}
Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x) = (x-x_0)^4$, where $x_0\in \mathbb{R}$ is constant. Suppose that we apply Newton's method to the problem of minimizing $f$, with iterates $x^{(0)},x^{(1)},x^{(2)},\dots$
\begin{enumerate}[label=\alph*.]
\item Write down the update equation for Newton's method applied to the
problem.
\item Let $y^{(k)}=|x^{(k)}-x_0|$, where $x^{(k)}$ is the $k$th iterate in
	Newton's method. Show that the sequence $\{y^{(k)}\}$ satisfies
	$y^{(k+1)}=\frac{2}{3}y^{(k)}$.
\item Show that $x^{(k)}\to x_0$ for any initial guess $x^{(0)}$.
\item Show that the order of convergence of the sequence $\{x^{(k)}\}$ in part
	b is 1.
\item Theorem 9.1 states that under certain conditions, the order of
	convergence of Newton's method is at least 2. Why does that theorem not
	hold in this particular problem?
\end{enumerate}
\subsection*{Solution a}
\subsection*{Solution b}
\subsection*{Solution c}
\subsection*{Solution d}
\subsection*{Solution e}
\section*{Exercise 9.4}
Consider Rosenbrock's function: $f(\bld{x})=100(x_2-x_1^2)^2+(1+x_1)^2$, where
$\bld{x}=[x_1,x_2]^T$. This function is also known as the banana function because of the shape of its level sets.
\begin{enumerate}[label=\alph*.]
\item Prove that $[1,1]^T$ is the unique global minimizer of $f$ over
	$\mathbb{R}^2$.
\item With a starting point of $[0,0]^T$, apply two iterations of Newton's
	method (with unit step size).
\item Repeat part b using a gradient algorithm with a fixed step size of
	$\alpha_k=0.05$ at each iteration.
\end{enumerate}
\subsection*{Solution a}
\subsection*{Solution b}
\subsection*{Solution c}
\end{document}
